{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40m2eu7_Vfcn",
        "outputId": "7c88f179-a80f-47e8-c2ad-33cf6f261744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (8.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download, install, import required tools"
      ],
      "metadata": {
        "id": "zfAehjVf0vw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwARqj5fWoMx",
        "outputId": "784e782a-fd07-4e74-f88b-1bf07e9d6549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize Text With Stopwords As Delimiters:\n",
        "\n",
        "Tokenize the given text with stop words (“is”,”the”,”was”) as delimiters. Tokenizing this way identifies meaningful phrases.\n"
      ],
      "metadata": {
        "id": "9dzEvSn5IYXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input :\n",
        "text =\"We are good students. We listen to all the lectures.\n",
        "\n"
      ],
      "metadata": {
        "id": "9puqALWlI4aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delimiters:\n",
        "\n",
        "\n",
        "*   Sequence of one or more characters.\n",
        "*   Separates independent regions.\n",
        "\n"
      ],
      "metadata": {
        "id": "GWkXxR4kI7mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop words removal\n"
      ],
      "metadata": {
        "id": "kuXXjMMCzqqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are stop words?\n",
        "\n",
        "> Eliminate words that are commonly used and carry little sense.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l1NefiHkz5Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBTrQ-yT3zpa",
        "outputId": "7c489e75-1923-4955-e405-1da51a52aa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "After_rmswd=[]\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for wd in t:\n",
        "  if wd not in stop_words:\n",
        "    After_rmswd.append(wd)\n",
        "print(After_rmswd)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNDPO1js1Cc6",
        "outputId": "2ea5ff99-3a31-4344-eaae-8d97219ecdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ram', 'good', 'boy', '(', 'ramK20LPU', '@', 'gmail.com', ')', '.', 'He', 'listening', 'lectures', 'attentively', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words removed here are 'is', 'a'"
      ],
      "metadata": {
        "id": "IEnkzVgt37Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add stop words(custom stop  word) and remove them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1SDekT9g4Ibv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_swd=[]\n",
        "add_stopword=[\"ram\",\".\",'(',')']\n",
        "for wd in After_rmswd:\n",
        "  if wd not in add_stopword:\n",
        "    custom_swd.append(wd)\n",
        "print(custom_swd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvHdV6V03ubp",
        "outputId": "e6eaf0e6-6bfd-4d0d-fe12-40ce26df7499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'boy', 'ramK20LPU', '@', 'gmail.com', 'He', 'listening', 'lectures', 'attentively']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Stemming:\n",
        " convert each token to it’s root form in the given text.\n",
        "\n"
      ],
      "metadata": {
        "id": "SPwccrh85-9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "After_stem=[]\n",
        "for wd in custom_swd:\n",
        "  After_stem.append(ps.stem(wd))\n",
        "print(After_stem)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Su1Ifp6u5I",
        "outputId": "bb242dfd-ef37-4a0e-e2aa-30399186cae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'boy', 'ramk20lpu', '@', 'gmail.com', 'he', 'listen', 'lectur', 'attent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ater stemming:\n",
        "listening -> listen\n",
        "lectures -> lectur\n",
        "attentively ->attent"
      ],
      "metadata": {
        "id": "l7tiqCNM9kSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization:\n",
        "\n",
        "Grouping together different forms of word considering the context and converts to meaningful root form(base) of every word."
      ],
      "metadata": {
        "id": "APUzBwSQ9x6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex:\n",
        "  \n",
        "\n",
        "*   Stemming of 'Charging ' -> charg\n",
        "*   Lemmatizationof 'Charging' -> Charge\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOBXJTG1_QWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Charge is the meaningful root form of word."
      ],
      "metadata": {
        "id": "28OMpBqO_prl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V0qddYRB7zd",
        "outputId": "642ed757-a99c-4768-d078-7339e7594eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open Multilingual Wordnet (OMW) downloading"
      ],
      "metadata": {
        "id": "PAktpdgmCsK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OMW English Wordnet based on WordNet 3.0 will beexported from this package."
      ],
      "metadata": {
        "id": "y7sHMY2lCvVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO9BdUAKDM8b",
        "outputId": "dbba1154-c603-4352-9cc5-e8b586e98290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import required module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#use to stopwords = nltk.corpus.stopwords.words('english')\n",
        "lm = WordNetLemmatizer()\n",
        "After_lm=[]\n",
        "for wd in custom_swd:\n",
        "  After_lm.append(lm.lemmatize(wd))\n",
        "print(After_lm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIh4hiP6AMU3",
        "outputId": "9321c3d0-5c85-4906-fac2-f601bea4aaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'boy', 'ramK20LPU', '@', 'gmail.com', 'He', 'listening', 'lecture', 'attentively']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Extracting Top Common Words -\n",
        "\n",
        "Extract the top 10 most common words in the given text excluding stopwords."
      ],
      "metadata": {
        "id": "R71pd-pqHzNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmn_wd=nltk.FreqDist(w.lower() for w in t if w not in nltk.corpus.stopwords.words('english')  )\n",
        "top_cmn_wd=cmn_wd.most_common(10)\n",
        "print(cmn_wd)\n",
        "print(top_cmn_wd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "225IIPaoHx5u",
        "outputId": "9d1b593d-2b1b-4acb-adaf-6e4878b05142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 13 samples and 14 outcomes>\n",
            "[('.', 2), ('ram', 1), ('good', 1), ('boy', 1), ('(', 1), ('ramk20lpu', 1), ('@', 1), ('gmail.com', 1), (')', 1), ('he', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FreqDist: A frequency distribution for the outcomes of an experiment.\n",
        "\n",
        "*  Records the number of times each outcome of an experiment has occurred.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6vDpzDFyQGWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "most_common\n",
        "\n",
        "*   Lists the n most common elements and their counts from the most common to the least.\n",
        "\n",
        "*   If n is None, then list all element counts.\n",
        "\n"
      ],
      "metadata": {
        "id": "UclexgtSS2D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS tagging"
      ],
      "metadata": {
        "id": "Nj8lhUb_V21c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk_ninDCRTSM",
        "outputId": "015beb5d-0ebb-4760-e594-8c162c639fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( nltk.pos_tag(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPuOpSmuWXoe",
        "outputId": "0fb9d47a-d485-4245-d673-18a5e039fbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ram', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('boy', 'NN'), ('(', '('), ('ramK20LPU', 'JJ'), ('@', 'NNP'), ('gmail.com', 'NN'), (')', ')'), ('.', '.'), ('He', 'PRP'), ('is', 'VBZ'), ('listening', 'VBG'), ('all', 'PDT'), ('the', 'DT'), ('lectures', 'NNS'), ('attentively', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}
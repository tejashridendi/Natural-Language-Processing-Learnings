{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (NLP) with Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "lW1b1rotayHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install Java, PySpark, and Spark NLP\n"
      ],
      "metadata": {
        "id": "LXn0JUyzokJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "# Install pyspark\n",
        "#! pip install --ignore-installed pyspark==3.1.2\n",
        "# Install Spark NLP\n",
        "#! pip install --ignore-installed spark-nlp==3.4.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzV9SdFnkd2u",
        "outputId": "9e764274-72a4-4aad-f289-3313c429d99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "openjdk version \"1.8.0_422\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_422-8u422-b05-1~22.04-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.422-b05, mixed mode)\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.2)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880746 sha256=6f43d4f4fe4113a4f4119aba4c16143e4905742fb3ed40d8fd4156c680f505f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.7 pyspark-3.1.2\n",
            "Collecting spark-nlp==3.4.3\n",
            "  Downloading spark_nlp-3.4.3-py2.py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spark_nlp-3.4.3-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.6/144.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall any pre-existing pyspark installations\n",
        "!pip uninstall -y pyspark\n",
        "!pip uninstall -y spark-nlp\n",
        "\n",
        "# Install the exact versions you need\n",
        "!pip install pyspark==3.1.2\n",
        "!pip install spark-nlp==3.4.3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "R2NGNzJAVFHO",
        "outputId": "a7f4b4c3-c6b3-480b-b490-40c1df12bf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyspark 3.5.3\n",
            "Uninstalling pyspark-3.5.3:\n",
            "  Successfully uninstalled pyspark-3.5.3\n",
            "\u001b[33mWARNING: Skipping spark-nlp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.2)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880746 sha256=70e8b721d90cb5732eb8bbadb173bb461448eccd79c5045bee95272e32966de3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Collecting spark-nlp==3.4.3\n",
            "  Downloading spark_nlp-3.4.3-py2.py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spark_nlp-3.4.3-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.6/144.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.4.3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "start() got an unexpected keyword argument 'spark31'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-235d8531073e>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark31\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure compatibility with Spark 3.1.x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spark NLP version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Apache Spark version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: start() got an unexpected keyword argument 'spark31'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ready to use PySpark and Spark NLP.**"
      ],
      "metadata": {
        "id": "DhiFWbSVjJc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import the relevant packages"
      ],
      "metadata": {
        "id": "dVD_I24NjA3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNVVk3xWB6L",
        "outputId": "eae43fa8-53c2-4ed9-dd7a-52ec3e45d73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.3\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Spark NLP is 3.4.3 and Apache Spark versions  just installed is 3.1.2**"
      ],
      "metadata": {
        "id": "co2k-eHipb2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the CoNLL dataset**"
      ],
      "metadata": {
        "id": "AbYYQGqPp3wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.train\"\n",
        "if not Path(download_path).is_file():\n",
        " print(\"File Not found will downloading it!\")\n",
        " url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
        " urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        " print(\"File already present.\")"
      ],
      "metadata": {
        "id": "mq2M6iKGkyM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bfc4ef0-d80e-4639-9081-d2119f146a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not found will downloading it!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.4 Convert the CoNLL file to Spark data frame\n",
        "\n",
        "Then we convert the CoNLL file to Spark data frame with all the additional fields generated to\n",
        "be used later on."
      ],
      "metadata": {
        "id": "m8XOsOKUz0Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.training import CoNLL\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show()"
      ],
      "metadata": {
        "id": "EZU-GEHzzzoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3396e9c8-6739-4238-f1a1-ae5fb7d549b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|\n",
            "|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|\n",
            "|The European Comm...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|\n",
            "|Germany 's repres...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
            "|\" We do n't suppo...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|\n",
            "|He said further s...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
            "|He said a proposa...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
            "|Fischler proposed...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, Fi...|[{pos, 0, 7, JJR,...|[{named_entity, 0...|\n",
            "|But Fischler agre...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Bu...|[{pos, 0, 2, CC, ...|[{named_entity, 0...|\n",
            "|Spanish Farm Mini...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 6, Sp...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
            "|                   .|[{document, 0, 0,...|[{document, 0, 0,...|[{token, 0, 0, .,...|[{pos, 0, 0, ., {...|[{named_entity, 0...|\n",
            "|Only France and B...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 3, On...|[{pos, 0, 3, RB, ...|[{named_entity, 0...|\n",
            "|The EU 's scienti...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|\n",
            "|Sheep have long b...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 4, Sh...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n",
            "|British farmers d...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Br...|[{pos, 0, 6, JJ, ...|[{named_entity, 0...|\n",
            "|\" What we have to...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|\n",
            "|Bonn has led effo...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 3, Bo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
            "|Germany imported ...|[{document, 0, 84...|[{document, 0, 84...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
            "|It brought in 4,2...|[{document, 0, 82...|[{document, 0, 82...|[{token, 0, 1, It...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.5 Word embedding\n",
        "The next step is to get the word embeddings through BERT. We will use a Spark NLP annotator\n",
        "called BertEmbeddings()."
      ],
      "metadata": {
        "id": "NYdlWplZ3uTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import BertEmbeddings\n",
        "bert = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
        ".setInputCols([\"sentence\",'token'])\\\n",
        ".setOutputCol(\"bert\")\\\n",
        ".setCaseSensitive(False)"
      ],
      "metadata": {
        "id": "8qLFB7Eu3yGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "489931fb-9a50-4d7c-f15c-c9b816e7292f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Spark NLP, we have four pre-trained variants of BERT\n",
        "\n",
        "• bert_base_uncased\n",
        "\n",
        "• bert_base_cased\n",
        "\n",
        "• bert_large_uncased\n",
        "\n",
        "• bert_large_cased\n",
        "\n",
        "‘Which one should be used?’ depends on your use case, training set, and the complexity of the\n",
        "task you are trying to model.\n",
        "In the code snippet above, we basically load the bert_base_cased version from Spark NLP public\n",
        "resources and point the sentence and token columns in setInputCols(). In short,\n",
        "BertEmbeddings() annotator will take the sentence and token columns and populate Bert\n",
        "embeddings in the bert column. In general, each word is translated to a 768-dimensional vector."
      ],
      "metadata": {
        "id": "azXeXGDE3zRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.6 Configuring Tagger\n",
        "\n",
        "Then we import the NerDLApproach() annotator, the main module responsible for training the\n",
        "NER model."
      ],
      "metadata": {
        "id": "43Phv9kv4AZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import NerDLApproach # Import NerDLApproach\n",
        "nerTagger = NerDLApproach()\\\n",
        ".setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        ".setLabelColumn(\"label\")\\\n",
        ".setOutputCol(\"ner\")\\\n",
        ".setMaxEpochs(1)\\\n",
        ".setRandomSeed(0)\\\n",
        ".setVerbose(1)\\\n",
        ".setValidationSplit(0.2)\\\n",
        ".setEvaluationLogExtended(True)\\\n",
        ".setEnableOutputLogs(True)\\\n",
        ".setIncludeConfidence(True)\\\n",
        ".setTestDataset(\"test_withEmbeds.parquet\")"
      ],
      "metadata": {
        "id": "77PBIypU4I_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".setInputCols([“sentence”, “token”, “bert”]) : the columns that will be used by the NER\n",
        "model to generate features.\n",
        "• .setLabelColumn(“label”) : the target columns\n",
        "• .setOutputCol(“ner”) : the predictions will be written to the ner column\n",
        "• .setMaxEpochs(1) : number of epochs for training\n",
        "• .setVerbose(1) : the level of logs while training\n",
        "• .setValidationSplit(0.2): the proportion of the training dataset to be validated against the\n",
        "model on each Epoch. The value should be between 0.0 and 1.0 and by default, it is 0.0\n",
        "and off.\n",
        "• .setEvaluationLogExtended(True): Whether logs for validation to be extended: it displays\n",
        "the time and evaluation of each label. The default is false.\n",
        "• .setEnableOutputLogs(True): Whether to output to the log folder. When set to True, the\n",
        "logs and training metrics will be written to the folder in the home folder.\n",
        "• .setIncludeConfidence(True): whether to include confidence scores in annotation\n",
        "metadata.\n",
        "• .setTestDataset(“test_withEmbeds.parquet”): The path to test dataset. If set, it is used to\n",
        "calculate statistics on it during training. This is also in a CoNLL format, but embeddings\n",
        "are added through and saved to disk as before. You don’t have to set this if you don’t\n",
        "need to evaluate your model on an unseen test set in Spark."
      ],
      "metadata": {
        "id": "_nbhwraQ4J8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.7.1 Download testing data\n"
      ],
      "metadata": {
        "id": "PJ33my1L4Qzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.testa\"\n",
        "if not Path(download_path).is_file():\n",
        " print(\"File Not found will downloading it!\")\n",
        " url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.testa\"\n",
        " urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        " print(\"File already present.\")"
      ],
      "metadata": {
        "id": "pv-vbrxn4kjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0166f73a-0e31-4c5c-a304-62daf51a26d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not found will downloading it!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.7.2 Transform and save\n",
        "Transform and save it as a parquet file. Apache Parquet is a columnar storage format"
      ],
      "metadata": {
        "id": "DraTBHIB4qXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "test_data = bert.transform(test_data)\n",
        "test_data.write.mode(\"overwrite\").parquet(\"test_withEmbeds.parquet\")"
      ],
      "metadata": {
        "id": "8moJlAYP40AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We  can also set the learning rate (setLr), learning rate decay coefficient (setPo), setBatchSize,\n",
        "and setDropout rate.\n",
        "\n",
        "Finally, the test result will be saved into test_withEmbeds.parquet file\n"
      ],
      "metadata": {
        "id": "-dwldFXx43pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.8 Training NER Model\n",
        "Now we can append these two annotators in a pipeline, then train the NER model with the\n",
        "training dataset"
      ],
      "metadata": {
        "id": "M0HMe8C05YLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "_r687hGWaOcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%time\n",
        "ner_pipeline = Pipeline(stages = [bert, nerTagger])\n",
        "ner_model = ner_pipeline.fit(training_data.limit(500))"
      ],
      "metadata": {
        "id": "0V5Ak98V5ZbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0552df-668d-4e24-b00c-7f416e64a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.22 s, sys: 140 ms, total: 1.36 s\n",
            "Wall time: 3min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.9 Testing (prediction)"
      ],
      "metadata": {
        "id": "X29R6yBE5chl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ner_model.transform(test_data.select(\"sentence\",\"token\",\"label\"))\n",
        "predictions.show()"
      ],
      "metadata": {
        "id": "7vS57KZz5uk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3250808-517f-41cc-cc8b-91d2d3891035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|            sentence|               token|               label|                bert|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|[{document, 0, 64...|[{token, 0, 6, CR...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 16...|[{token, 0, 5, LO...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 18...|[{token, 0, 3, We...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 20...|[{token, 0, 4, Th...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 21...|[{token, 0, 4, Af...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 12...|[{token, 0, 7, Tr...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 16...|[{token, 0, 4, Es...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 18...|[{token, 0, 6, Hu...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 20...|[{token, 0, 1, By...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 21...|[{token, 0, 1, At...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 11...|[{token, 0, 1, He...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 19...|[{token, 0, 9, De...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 14...|[{token, 0, 9, Au...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 15...|[{token, 0, 4, Af...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 11...|[{token, 0, 3, Th...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 41...|[{token, 0, 1, By...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 45...|[{token, 0, 6, CR...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 16...|[{token, 0, 5, LO...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 81...|[{token, 0, 5, Re...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "|[{document, 0, 67...|[{token, 0, 8, Le...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"token.result\",\"label.result\",\"ner.result\").show(truncate=40)"
      ],
      "metadata": {
        "id": "MsW8ysrX6BKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465eba76-9458-44c5-bf06-8cf0af9f83ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                  result|                                  result|                                  result|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|[CRICKET, -, LEICESTERSHIRE, TAKE, OV...|   [O, O, I-ORG, O, O, O, O, O, O, O, O]|   [O, O, I-PER, O, O, O, O, O, O, O, O]|\n",
            "|                    [LONDON, 1996-08-30]|                              [I-LOC, O]|                              [I-LOC, O]|\n",
            "|[West, Indian, all-rounder, Phil, Sim...|[I-MISC, I-MISC, O, I-PER, I-PER, O, ...|[O, I-PER, O, I-PER, I-PER, O, O, O, ...|\n",
            "|[Their, stay, on, top, ,, though, ,, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[After, bowling, Somerset, out, for, ...|[O, O, I-ORG, O, O, O, O, O, O, O, O,...|[O, O, I-PER, O, O, O, O, O, O, O, O,...|\n",
            "|[Trailing, by, 213, ,, Somerset, got,...|[O, O, O, O, I-ORG, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Essex, ,, however, ,, look, certain,...|[I-ORG, O, O, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Hussain, ,, considered, surplus, to,...|[I-PER, O, O, O, O, I-LOC, O, O, O, O...|[O, O, O, O, O, I-PER, O, O, O, O, O,...|\n",
            "|[By, the, close, Yorkshire, had, turn...|[O, O, O, I-ORG, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[At, the, Oval, ,, Surrey, captain, C...|[O, O, I-LOC, O, I-ORG, O, I-PER, I-P...|[O, O, O, O, I-PER, O, I-PER, I-PER, ...|\n",
            "|[He, was, well, backed, by, England, ...|[O, O, O, O, O, I-LOC, O, I-PER, I-PE...|[O, O, O, O, O, I-PER, O, O, O, O, O,...|\n",
            "|[Derbyshire, kept, up, the, hunt, for...|[I-ORG, O, O, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[Australian, Tom, Moody, took, six, f...|[I-MISC, I-PER, I-PER, O, O, O, O, O,...|[O, I-PER, I-PER, O, O, O, O, O, I-PE...|\n",
            "|[After, the, frustration, of, seeing,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[They, were, held, up, by, a, gritty,...|[O, O, O, O, O, O, O, O, O, I-PER, I-...|[O, O, O, O, O, O, O, O, O, I-PER, I-...|\n",
            "|[By, stumps, Kent, had, reached, 108,...|         [O, O, I-ORG, O, O, O, O, O, O]|             [O, O, O, O, O, O, O, O, O]|\n",
            "|[CRICKET, -, ENGLISH, COUNTY, CHAMPIO...|    [O, O, I-MISC, I-MISC, I-MISC, O, O]|                   [O, O, O, O, O, O, O]|\n",
            "|                    [LONDON, 1996-08-30]|                              [I-LOC, O]|                              [I-LOC, O]|\n",
            "|[Result, and, close, of, play, scores...|[O, O, O, O, O, O, O, I-MISC, O, O, O...|[O, O, O, O, O, O, O, I-PER, O, O, O,...|\n",
            "|[Leicester, :, Leicestershire, beat, ...|[I-LOC, O, I-ORG, O, I-ORG, O, O, O, ...|[O, O, I-PER, O, I-PER, O, O, O, O, O...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.printSchema()"
      ],
      "metadata": {
        "id": "PmPr3pCz6Ndr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932dad1f-b3b0-4128-b76f-dd2178e45f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sentence: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- label: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- bert: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "metadata": {
        "id": "pomNRfOP6XGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05a1185-f63e-40de-a74e-90cbd99522e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|I-ORG       |I-PER     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |I-LOC       |I-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |I-MISC      |O         |\n",
            "|Indian        |I-MISC      |I-PER     |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |I-PER       |I-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Annotate (NER) a text using a PretrainedPipeline (recognize_entities_dl) in SparkNLP [10][11]**\n",
        "**and show the results of annotated (named entity) text**\n",
        "**• Input Text from Wikipedia**\n",
        "\n",
        "The University of Illinois Springfield (UIS) is a public university in Springfield,\n",
        "Illinois, United States. As a public liberal arts college and the newest campus in\n",
        "the University of Illinois system, UIS is a member of the Council of Public Liberal\n",
        "Arts Colleges. UIS is also part of the American Association of State Colleges and\n",
        "Universities and the American Council on Education. The campus' main repository,\n",
        "Brookens Library, holds a collection of nearly 800,000 books and serials in addition\n",
        "to accessible resources at the University of Illinois Chicago and University of\n",
        "Illinois Urbana-Champaign campuses. President: Timothy L. Killeen. Chancellor: Janet\n",
        "L. Gooch. Location: Springfield, Illinois, United States.\n",
        "\n",
        "**To show the named entity of each word, the output style should be like the one below.**\n",
        "[('The', 'O'),\n",
        " ('University', 'B-ORG'),\n",
        " ('of', 'I-ORG'),\n",
        " ('Illinois', 'I-ORG'),\n",
        " ('Springfield', 'I-ORG'),\n",
        " ('(', 'O'),\n",
        " ('UIS', 'B-ORG'),\n",
        " (')', 'O'),\n",
        " ('is', 'O'),\n",
        " ('a', 'O'),\n",
        " ('public', 'O'),\n",
        "... (skipped)"
      ],
      "metadata": {
        "id": "jsaCGzN9keJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "pretrain_pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')\n",
        "nert=\"The University of Illinois Springfield (UIS) is a public university in Springfield, Illinois, United States. As a public liberal arts college and the newest campus in the University of Illinois system, UIS is a member of the Council of Public Liberal Arts Colleges. UIS is also part of the American Association of State Colleges and Universities and the American Council on Education. The campus' main repository, Brookens Library, holds a collection of nearly 800,000 books and serials in addition to accessible resources at the University of Illinois Chicago and University of Illinois Urbana-Champaign campuses. President: Timothy L. Killeen. Chancellor: Janet L. Gooch. Location: Springfield, Illinois, United States.\"\n",
        "res=pretrain_pipeline.annotate(nert)\n",
        "list(zip(res['token'], res['ner']))"
      ],
      "metadata": {
        "id": "kj5MR0EkYt9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6c8b8e-3cef-4bc0-98f4-37fe9d1b0e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 160.1 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'O'),\n",
              " ('University', 'B-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('Illinois', 'I-ORG'),\n",
              " ('Springfield', 'I-ORG'),\n",
              " ('(', 'O'),\n",
              " ('UIS', 'B-ORG'),\n",
              " (')', 'O'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('public', 'O'),\n",
              " ('university', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Springfield', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('Illinois', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('States', 'I-LOC'),\n",
              " ('.', 'O'),\n",
              " ('As', 'O'),\n",
              " ('a', 'O'),\n",
              " ('public', 'O'),\n",
              " ('liberal', 'O'),\n",
              " ('arts', 'O'),\n",
              " ('college', 'O'),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('newest', 'O'),\n",
              " ('campus', 'O'),\n",
              " ('in', 'O'),\n",
              " ('the', 'O'),\n",
              " ('University', 'B-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('Illinois', 'I-ORG'),\n",
              " ('system', 'O'),\n",
              " (',', 'O'),\n",
              " ('UIS', 'B-ORG'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('member', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Council', 'B-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('Public', 'I-ORG'),\n",
              " ('Liberal', 'I-ORG'),\n",
              " ('Arts', 'I-ORG'),\n",
              " ('Colleges', 'I-ORG'),\n",
              " ('.', 'O'),\n",
              " ('UIS', 'B-ORG'),\n",
              " ('is', 'O'),\n",
              " ('also', 'O'),\n",
              " ('part', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('American', 'B-ORG'),\n",
              " ('Association', 'I-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('State', 'I-ORG'),\n",
              " ('Colleges', 'I-ORG'),\n",
              " ('and', 'I-ORG'),\n",
              " ('Universities', 'I-ORG'),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('American', 'B-ORG'),\n",
              " ('Council', 'I-ORG'),\n",
              " ('on', 'I-ORG'),\n",
              " ('Education', 'I-ORG'),\n",
              " ('.', 'O'),\n",
              " ('The', 'O'),\n",
              " ('campus', 'O'),\n",
              " (\"'\", 'O'),\n",
              " ('main', 'O'),\n",
              " ('repository', 'O'),\n",
              " (',', 'O'),\n",
              " ('Brookens', 'B-ORG'),\n",
              " ('Library', 'I-ORG'),\n",
              " (',', 'O'),\n",
              " ('holds', 'O'),\n",
              " ('a', 'O'),\n",
              " ('collection', 'O'),\n",
              " ('of', 'O'),\n",
              " ('nearly', 'O'),\n",
              " ('800,000', 'O'),\n",
              " ('books', 'O'),\n",
              " ('and', 'O'),\n",
              " ('serials', 'O'),\n",
              " ('in', 'O'),\n",
              " ('addition', 'O'),\n",
              " ('to', 'O'),\n",
              " ('accessible', 'O'),\n",
              " ('resources', 'O'),\n",
              " ('at', 'O'),\n",
              " ('the', 'O'),\n",
              " ('University', 'B-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('Illinois', 'I-ORG'),\n",
              " ('Chicago', 'I-ORG'),\n",
              " ('and', 'O'),\n",
              " ('University', 'B-ORG'),\n",
              " ('of', 'I-ORG'),\n",
              " ('Illinois', 'I-ORG'),\n",
              " ('Urbana-Champaign', 'I-ORG'),\n",
              " ('campuses', 'O'),\n",
              " ('.', 'O'),\n",
              " ('President', 'O'),\n",
              " (':', 'O'),\n",
              " ('Timothy', 'B-PER'),\n",
              " ('L', 'I-PER'),\n",
              " ('.', 'O'),\n",
              " ('Killeen', 'B-PER'),\n",
              " ('.', 'O'),\n",
              " ('Chancellor', 'O'),\n",
              " (':', 'O'),\n",
              " ('Janet', 'B-PER'),\n",
              " ('L', 'I-PER'),\n",
              " ('.', 'O'),\n",
              " ('Gooch', 'B-PER'),\n",
              " ('.', 'O'),\n",
              " ('Location', 'O'),\n",
              " (':', 'O'),\n",
              " ('Springfield', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('Illinois', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('United', 'B-LOC'),\n",
              " ('States', 'I-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}